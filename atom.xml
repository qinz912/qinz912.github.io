<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Miguel</title>
  
  <subtitle>Stay hungry,stay foolish.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://qinz912.github.io/"/>
  <updated>2019-02-27T06:17:51.177Z</updated>
  <id>https://qinz912.github.io/</id>
  
  <author>
    <name>Miguel</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>hadopon相关</title>
    <link href="https://qinz912.github.io/2019/02/27/hadopon%E7%9B%B8%E5%85%B3/"/>
    <id>https://qinz912.github.io/2019/02/27/hadopon相关/</id>
    <published>2019-02-27T06:15:58.000Z</published>
    <updated>2019-02-27T06:17:51.177Z</updated>
    
    <content type="html"><![CDATA[<h3 id="hadoop1-X和hadoop2-X有什么区别？"><a href="#hadoop1-X和hadoop2-X有什么区别？" class="headerlink" title="hadoop1.X和hadoop2.X有什么区别？"></a>hadoop1.X和hadoop2.X有什么区别？</h3><ul><li>1.x中MapReduce既做计算也做资源调度</li><li>2.x中将资源调度单独成一个模块：Yarn。Yarn负责资源调度，MapReduce负责计算，有利于解耦。</li></ul><h3 id="hadoop的组成"><a href="#hadoop的组成" class="headerlink" title="hadoop的组成"></a>hadoop的组成</h3><ul><li>NameNode(nn)：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</li><li>DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和</li><li>Secondary NameNode(2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。</li></ul><h3 id="Yarn的架构"><a href="#Yarn的架构" class="headerlink" title="Yarn的架构"></a>Yarn的架构</h3><blockquote><p>ResourceManager（RM）主要作用如下</p><ul><li>处理客户端请求</li><li>监控NodeManager</li><li>启动或监控ApplicationMaster</li><li>资源的分配与调度</li></ul></blockquote><blockquote><p>NodeManager（NM）主要作用如下</p><ul><li>管理单个节点上的资源</li><li>处理来自RM的命令</li><li>处理来自ApplicationMaster的命令</li></ul></blockquote><blockquote><p>ApplicationMaster（AM）的主要作用如下</p><ul><li>负责数据的切分</li><li>为应用程序申请资源并分配给内部的任务</li><li>任务的监控与容错</li></ul></blockquote><blockquote><p>Container（为AM提供资源）</p><ul><li>Container是Yarn中的资源抽象，它封装了某个节点上的多维度资源，如：内存、CPU、磁盘、网络等。</li></ul></blockquote><h3 id="MapReduce的架构"><a href="#MapReduce的架构" class="headerlink" title="MapReduce的架构"></a>MapReduce的架构</h3><blockquote><p>MapReduce将计算过程分为两个阶段：Map和Reduce</p><ul><li>Map阶段并行处理输入数据</li><li>Reduce阶段对Map结果进行汇总</li></ul></blockquote><h3 id="Hadoop安装步骤"><a href="#Hadoop安装步骤" class="headerlink" title="Hadoop安装步骤"></a>Hadoop安装步骤</h3><ol><li><p>安装jdk</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a、先获取jdk路径，然后在/etc/profile文件末尾添加</span><br><span class="line">    export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br><span class="line">    export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">b、让文件生效：source  /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>安装Hadoop</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a、解压hadoop包</span><br><span class="line">b、配置hadoop-env.sh中的$JAVA_HOME，改为jdk路径</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br><span class="line">c、将hadoop配置到环境变量</span><br><span class="line">在/etc/profile文件末尾添加</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-2.7.2</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line">d、让文件生效：source  /etc/profile</span><br></pre></td></tr></table></figure></li></ol><h3 id="伪分布式配置hadoop"><a href="#伪分布式配置hadoop" class="headerlink" title="伪分布式配置hadoop"></a>伪分布式配置hadoop</h3><ol><li><p>配置：core-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">    &lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://hadoop101:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>配置：hdfs-site.xml  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">   &lt;!-- 指定HDFS副本的数量 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">&lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>启动集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   （a）格式化namenode（第一次启动时格式化，以后就不要总格式化）</span><br><span class="line">bin/hdfs namenode -format</span><br><span class="line">（b）启动namenode</span><br><span class="line">sbin/hadoop-daemon.sh start namenode</span><br><span class="line">（c）启动datanode</span><br><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></li></ol><p>==tips:jps是jdk的命令，查看java进程==<br>==tips:见到env后缀的文件，都吧$JAVA_HOME改为jdk路径==</p><ol start="4"><li><p>配置Yarn</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">   （a）配置yarn-env.sh</span><br><span class="line">   配置一下JAVA_HOME</span><br><span class="line">       export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br><span class="line">   （b）配置yarn-site.xml</span><br><span class="line">       &lt;!-- reducer获取数据的方式 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">       &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;hadoop101&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">（c）配置：mapred-env.sh</span><br><span class="line">   配置一下JAVA_HOME</span><br><span class="line">       export JAVA_HOME=/opt/module/jdk1.7.0_79</span><br><span class="line">（d）配置： (对mapred-site.xml.template重新命名为) mapred-site.xml</span><br><span class="line">       &lt;!-- 指定mr运行在yarn上 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br></pre></td></tr></table></figure></li><li><p>历史服务器的配置（默认端口19888）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">   1）配置mapred-site.xml</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;hadoop101:10020&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;hadoop101:19888&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">2）查看启动历史服务器文件目录：</span><br><span class="line">       [root@hadoop101 hadoop-2.7.2]# ls sbin/ |grep mr</span><br><span class="line">       mr-jobhistory-daemon.sh</span><br><span class="line">3）启动历史服务器</span><br><span class="line">       sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;hadoop1-X和hadoop2-X有什么区别？&quot;&gt;&lt;a href=&quot;#hadoop1-X和hadoop2-X有什么区别？&quot; class=&quot;headerlink&quot; title=&quot;hadoop1.X和hadoop2.X有什么区别？&quot;&gt;&lt;/a&gt;hadoop1.X和h
      
    
    </summary>
    
      <category term="hadoop" scheme="https://qinz912.github.io/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="https://qinz912.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://qinz912.github.io/2019/02/27/hello-world/"/>
    <id>https://qinz912.github.io/2019/02/27/hello-world/</id>
    <published>2019-02-27T01:06:11.796Z</published>
    <updated>2019-02-27T01:06:11.797Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
