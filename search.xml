<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[照片]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%85%A7%E7%89%87%2F</url>
    <content type="text"><![CDATA[照片]]></content>
      <tags>
        <tag>情感</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hadopon相关]]></title>
    <url>%2F2019%2F02%2F27%2Fhadopon%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[hadoop1.X和hadoop2.X有什么区别？ 1.x中MapReduce既做计算也做资源调度 2.x中将资源调度单独成一个模块：Yarn。Yarn负责资源调度，MapReduce负责计算，有利于解耦。 hadoop的组成 NameNode(nn)：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。 DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和 Secondary NameNode(2nn)：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照。 Yarn的架构 ResourceManager（RM）主要作用如下 处理客户端请求 监控NodeManager 启动或监控ApplicationMaster 资源的分配与调度 NodeManager（NM）主要作用如下 管理单个节点上的资源 处理来自RM的命令 处理来自ApplicationMaster的命令 ApplicationMaster（AM）的主要作用如下 负责数据的切分 为应用程序申请资源并分配给内部的任务 任务的监控与容错 Container（为AM提供资源） Container是Yarn中的资源抽象，它封装了某个节点上的多维度资源，如：内存、CPU、磁盘、网络等。 MapReduce的架构 MapReduce将计算过程分为两个阶段：Map和Reduce Map阶段并行处理输入数据 Reduce阶段对Map结果进行汇总 Hadoop安装步骤 安装jdk 1234a、先获取jdk路径，然后在/etc/profile文件末尾添加 export JAVA_HOME=/opt/module/jdk1.7.0_79 export PATH=$PATH:$JAVA_HOME/binb、让文件生效：source /etc/profile 安装Hadoop 123456789a、解压hadoop包b、配置hadoop-env.sh中的$JAVA_HOME，改为jdk路径export JAVA_HOME=/opt/module/jdk1.7.0_79c、将hadoop配置到环境变量在/etc/profile文件末尾添加export HADOOP_HOME=/opt/module/hadoop-2.7.2export PATH=$PATH:$HADOOP_HOME/binexport PATH=$PATH:$HADOOP_HOME/sbin d、让文件生效：source /etc/profile 伪分布式配置hadoop 配置：core-site.xml 1234567891011 &lt;!-- 指定HDFS中NameNode的地址 --&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop101:9000&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-2.7.2/data/tmp&lt;/value&gt;&lt;/property&gt; 配置：hdfs-site.xml 12345 &lt;!-- 指定HDFS副本的数量 --&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt; 启动集群 123456 （a）格式化namenode（第一次启动时格式化，以后就不要总格式化） bin/hdfs namenode -format（b）启动namenode sbin/hadoop-daemon.sh start namenode（c）启动datanode sbin/hadoop-daemon.sh start datanode ==tips:jps是jdk的命令，查看java进程====tips:见到env后缀的文件，都吧$JAVA_HOME改为jdk路径== 配置Yarn 123456789101112131415161718192021222324 （a）配置yarn-env.sh 配置一下JAVA_HOME export JAVA_HOME=/opt/module/jdk1.7.0_79 （b）配置yarn-site.xml &lt;!-- reducer获取数据的方式 --&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定YARN的ResourceManager的地址 --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop101&lt;/value&gt; &lt;/property&gt;（c）配置：mapred-env.sh 配置一下JAVA_HOME export JAVA_HOME=/opt/module/jdk1.7.0_79（d）配置： (对mapred-site.xml.template重新命名为) mapred-site.xml &lt;!-- 指定mr运行在yarn上 --&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; 历史服务器的配置（默认端口19888） 1234567891011121314 1）配置mapred-site.xml &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;hadoop101:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;hadoop101:19888&lt;/value&gt; &lt;/property&gt;2）查看启动历史服务器文件目录： [root@hadoop101 hadoop-2.7.2]# ls sbin/ |grep mr mr-jobhistory-daemon.sh3）启动历史服务器 sbin/mr-jobhistory-daemon.sh start historyserver]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F02%2F27%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
